{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5706b7f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' January 2022 Data \\nOne can input these into the variation_plot function, or any of the runs into the run_time_delta_computation or statistics_plot functions.\\n'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" This script is used to compute and plot the time deltas of the CMS ECAL prototype from the ETH group at the CERN Prevessin site.\n",
    "The mainly used functions to call from outside the script are down below: run_time_delta_computation, statistics_plot, variation_plot, and variation_statistics.\n",
    "\"\"\"\n",
    "\n",
    "\"\"\" Imports \"\"\"\n",
    "\n",
    "import uproot\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import h5py\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.optimize import curve_fit\n",
    "from decimal import *\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "\"\"\" Global Variables \"\"\"\n",
    "\n",
    "save_folder_global = 'Synchronisation' # Processed data from time delta computation will be stored in a folder named like this. \n",
    "                                        # The data from January 2022 is in 'Synchronisation January 2022'\n",
    "raw_data_folder_global = '/eos/home-s/spigazzi/Lab21/data/Reco/' # Raw data is stored here\n",
    "variation_save_folder_global = 'Variation Stats ' # Variation plots are saved here\n",
    "split_name = 'Merged' # Needed for legacy support, namely to be able to run the statistics_plot and variation plot functions \n",
    "                    # on the data files from January 2022 with 'Merged in their name'. Obsolete otherwise, split_name could be removed everywhere \n",
    "\n",
    "numbers = ['1', '2', '3', '4', '5'] # The five channels on each board\n",
    "letters = ['A', 'B', 'D', 'E'] # TODO: Add Back 'C' when board 20 (middle board) is back. It was out of order in January 2022\n",
    "\n",
    "X = numbers.copy() # Used for colormesh plots\n",
    "Y = letters.copy()\n",
    "X.insert(0, '0')\n",
    "Y.insert(0, '0')\n",
    "\n",
    "channel_names = ['A1', 'A2', 'A3', 'A4', 'A5', \n",
    "                 'B1', 'B2', 'B3', 'B4', 'B5', # TODO: Add C when board C returns\n",
    "                 'D1', 'D2', 'D3', 'D4', 'D5',\n",
    "                 'E1', 'E2', 'E3', 'E4', 'E5']\n",
    "\n",
    "\"\"\" Helper Functions \"\"\"\n",
    "\n",
    "def gaussian(x, *p):\n",
    "    A, mu, sigma = p\n",
    "    return A * np.exp(-(x -mu)**2/(2*sigma**2))\n",
    "\n",
    "\n",
    "def synchroniser(value):\n",
    "    \"\"\" Function to remove the period shift. Collects the scattered peaks separated by integer multiples of the clock period to one large peak \"\"\"\n",
    "    clock_period = 6.238 # nanoseconds    \n",
    "    window_leniency = 0.5 # How far from the center value the synchroniser should start to act. Minimum Value that makes sense physically: 0.5\n",
    "    if value > 0:\n",
    "        while value > clock_period * window_leniency:\n",
    "            value -= clock_period\n",
    "    else:\n",
    "        while value < (-clock_period * window_leniency):\n",
    "            value += clock_period\n",
    "    return float(Decimal(value) % Decimal(clock_period))\n",
    "\n",
    "\n",
    "def temperature_conversion(resistance):\n",
    "    \"\"\" Takes resistance in Ohm. Returns temperature calculated from the measured resistance of the temperature sensor reader \"\"\"\n",
    "    nominal_resistance = 1000 # in Ohm\n",
    "    mean_coefficient = 3.91e-3 # in K^-1, for the plantinum resistance thermometer Pt1000\n",
    "    return (np.abs(resistance - nominal_resistance))/(mean_coefficient * nominal_resistance)\n",
    "\n",
    "\n",
    "def to_channel_converter(channel_number):\n",
    "    \"\"\" Converts the channel number to the appropriate Channel. For example 7 -> 'B3'. \"\"\"\n",
    "    board_counter = 0\n",
    "    while channel_number > 4:\n",
    "        board_counter += 1\n",
    "        channel_number -= 5\n",
    "    return f'{letters[board_counter]}{numbers[channel_number]}'\n",
    "    \n",
    "\n",
    "def compute_time_delta(time, reference_channel_index, run_name, split_name='Merged', plot=True, apply_synchroniser=True):\n",
    "    \"\"\" Computes the time difference (delta) for a given reference channel to all the other channels. \n",
    "    Also returns the mu and sigma statistics and their errors.\"\"\"\n",
    "    time_pd = pd.DataFrame(time)\n",
    "    n_channels = len(letters) * 5\n",
    "    \n",
    "    time_delta_pd = pd.DataFrame()\n",
    "    mu_arr = np.zeros(n_channels)\n",
    "    mu_error_arr = np.zeros(n_channels)\n",
    "    sigma_arr = np.zeros(n_channels)\n",
    "    sigma_error_arr = np.zeros(n_channels)\n",
    "    for i in range(n_channels):\n",
    "        if i == reference_channel_index:\n",
    "            continue\n",
    "            \n",
    "        reference_time = time_pd.iloc[:,reference_channel_index]\n",
    "        curr_time = time_pd.iloc[:,i]\n",
    "        time_delta = reference_time - curr_time\n",
    "\n",
    "        # Remove period shift from the data\n",
    "        if apply_synchroniser: \n",
    "            time_delta = time_delta.apply(synchroniser)\n",
    "        \n",
    "        time_delta = time_delta.multiply(1000)\n",
    "        \n",
    "        # Save time deltas for later analysis\n",
    "        time_delta_pd[f'{i}'] = time_delta\n",
    "\n",
    "        plt.figure()\n",
    "        border_size = 2000\n",
    "        plt.xlim((-border_size,border_size))\n",
    "\n",
    "        # The fitting process\n",
    "        hist, bin_edges, _ = plt.hist(time_delta, bins = 1500, label='Time Delta Histogram')\n",
    "        bin_centers = ((bin_edges[:-1] + bin_edges[1:]) / 2)  \n",
    "        guess = [np.max(hist), bin_centers[np.argmax(hist)], 300]\n",
    "        coeff, covar = curve_fit(gaussian, bin_centers, hist, p0=guess)\n",
    "        mu = coeff[1]\n",
    "        mu_error = covar[1,1]\n",
    "        sigma = coeff[2]\n",
    "        sigma_error = covar[2,2]\n",
    "        mu_arr[i] = mu\n",
    "        mu_error_arr[i] = mu_error\n",
    "        sigma_arr[i] = sigma\n",
    "        sigma_error_arr[i] = sigma_error\n",
    "        \n",
    "        if plot:\n",
    "            plt.plot(bin_centers, gaussian(bin_centers, *coeff), label='Gaussian Fit')\n",
    "            plt.axvline(mu, label = f'Mean: {np.around(mu, decimals = 1)} ps', color = 'red')\n",
    "            sigma_color = 'pink'\n",
    "            plt.axvline(mu + sigma, label = f'Std Dev: {np.around(sigma, decimals = 1)} ps', color = sigma_color)\n",
    "            plt.axvline(mu - sigma, color = sigma_color)\n",
    "            plt.title(f'Reference Channel: {to_channel_converter(reference_channel_index)}, Run: {run_name}, Channel {to_channel_converter(i)}')\n",
    "            plt.xlabel('Time Delta (ps)')\n",
    "            plt.ylabel('Occurence (a.u.)')\n",
    "            plt.legend(loc='best')\n",
    "            \n",
    "    plt.show()\n",
    "\n",
    "    return time_delta_pd, mu_arr.reshape(-1,1), mu_error_arr.reshape(-1,1), sigma_arr.reshape(-1,1), sigma_error_arr.reshape(-1,1)\n",
    "\n",
    "\n",
    "\"\"\" Main functions to run from outside script \"\"\"\n",
    "\n",
    "def run_time_delta_computation(run_number, save_folder = save_folder_global, raw_data_folder = raw_data_folder_global):\n",
    "    \"\"\" Computes the time deltas for a run. The splits are merged into a single big run number and the time deltas are saved in an h5 file.\n",
    "    \n",
    "    run_number -- (string or int) the number of a run, for example '15484'\n",
    "    save_folder -- (string) folder where the computed data should be stored\n",
    "    raw_data_folder -- (string) folder where the raw experiment data is located\n",
    "    \"\"\"\n",
    "    \n",
    "    # Computation with merged data\n",
    "    folder =  raw_data_folder + str(int(run_number))\n",
    "    h = uproot.concatenate({folder+'/*.root' : 'digi'}, allow_missing = True)\n",
    "    \n",
    "    run_name = os.path.basename(os.path.normpath(folder))\n",
    "    print('Run: ', run_name, ' Split: ', split_name)\n",
    "    run_save = save_folder + '/Run ' + run_name + '/' + split_name + '/'\n",
    "    Path(run_save).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    for ref_channel in channel_names:       \n",
    "        ref_idx = h[ref_channel][0]\n",
    "        time = h['time_max']\n",
    "        time_pd = pd.DataFrame(time)\n",
    "\n",
    "        time_delta_data, mu_arr, mu_error_arr, sigma_arr, sigma_error_arr  = compute_time_delta(time, ref_idx, run_name)\n",
    "        statistics = np.hstack((mu_arr, mu_error_arr, sigma_arr, sigma_error_arr))\n",
    "        time_delta_data.to_hdf(run_save + f'Time Delta Run {run_name} ref_ch {ref_channel}.h5', key='df', mode='w')\n",
    "        with h5py.File(run_save + 'Statistics Split ' + split_name + f' ref_ch {ref_channel}.h5', 'w') as hf:\n",
    "            hf.create_dataset(\"stats\",  data=statistics)\n",
    "            \n",
    "\n",
    "def statistics_plot(run_number, save_folder=save_folder_global, raw_data_folder=raw_data_folder_global, skip_mu=False):\n",
    "    \"\"\" Plots mu and sigma as well as their errors for the time deltas of a designated run in a colormesh plot.\n",
    "    One has to have run the run_time_delta_computation function on the designated run first before using this function.\n",
    "    \n",
    "    run_number -- (string or int) The number of a run, for example '15484'\n",
    "    save_folder -- (string) Folder where the computed data should be stored\n",
    "    raw_data_folder -- (string) Folder where the raw experiment data is located\n",
    "    skip_mu == (boolean) If one is not interested in mu, one can skip plotting it\n",
    "    \"\"\"\n",
    "    \n",
    "    stat_names = ['Mu', 'Mu error', 'Sigma', 'Sigma_error']\n",
    "    folder =  raw_data_folder + str(int(run_number))\n",
    "    run_name = os.path.basename(os.path.normpath(folder))\n",
    "    print('Run: ', run_name, ' Split: ', split_name)\n",
    "    run_save = save_folder + '/Run ' + str(run_name) + '/' + split_name + '/'\n",
    "    Path(run_save).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    for k, ref_channel in enumerate(channel_names):\n",
    "        with h5py.File(run_save + 'Statistics Split ' + split_name + f' ref_ch {ref_channel}.h5', 'r') as hf:\n",
    "            statistics = hf[f\"stats\"][:]\n",
    "            \n",
    "        for i in range(len(statistics[0,:])):\n",
    "            if skip_mu and ((i == 0) or (i ==1)):\n",
    "                continue\n",
    "                \n",
    "            plt.figure()\n",
    "            stat_data = statistics[:,i].reshape(4,5)\n",
    "            c = plt.pcolormesh(X, Y, stat_data*1000)\n",
    "            cb = plt.colorbar(c)\n",
    "            cb.set_label('Deviation over Channels (ps)')\n",
    "            plt.title(f'{stat_names[i]}, Run: {run_name}, Split: {split_name}, Reference Channel: {ref_channel}')\n",
    "            plt.show()\n",
    "        plt.savefig(run_save + f'Stats Colormesh Ref Channel {to_channel_converter(k)}.pdf', dpi = 300)\n",
    "        \n",
    "\n",
    "def variation_plot(measurement_name, measurement_date, included_runs, mu_range = 2000, sigma_range = 150, specific_ref_channel='all'):\n",
    "    \"\"\"Plots the evolution of the mu and sigma statistics and their errors over a number of runs.\n",
    "    \n",
    "    measurement_name -- (string) Title of the measurement, for example power cycle or temperature\n",
    "    measurement_date -- (string) Date of the measurement. Originally used to distinguish between series of runs, \n",
    "                        but the date will not be unique enough for future measurements.\n",
    "                        Could and should be replaced by a unique identifier, like an ID for a batch of runs.\n",
    "    included_runs -- (list of strings or ints) List of all the runs to include in our variation plot.\n",
    "    mu_range -- (number) Maximum and minimum of which mu values will be visible in the plot\n",
    "    sigma_range -- (number) Maximum and minimum of which sigma values will be visible in the plot\n",
    "    specific_ref_channel -- (string) If one wants to test the function only for a specific channel, use that channel here, for example 'B3'\n",
    "    \"\"\"\n",
    "    \n",
    "    save_folder = save_folder_global\n",
    "    variation_save = variation_save_folder_global + '/' + measurement_name + '/' + measurement_date + '/'\n",
    "    Path(variation_save).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    for q, ref_channel in enumerate(channel_names):\n",
    "        if specific_ref_channel != 'all':\n",
    "            q = 0\n",
    "            if ref_channel != specific_ref_channel:\n",
    "                continue\n",
    "\n",
    "        for k, run_name in enumerate(included_runs):\n",
    "            run_save = save_folder + '/Run ' + str(run_name) + '/' + split_name + '/'\n",
    "            if k==0:\n",
    "                with h5py.File(run_save + 'Statistics Split ' + split_name + f' ref_ch {ref_channel}.h5', 'r') as hf:\n",
    "                    stacked_average_stats = hf[f\"stats\"][:]\n",
    "            else:\n",
    "                with h5py.File(run_save + 'Statistics Split ' + split_name + f' ref_ch {ref_channel}.h5', 'r') as hf:\n",
    "                    stacked_average_stats = np.dstack((stacked_average_stats, hf[f\"stats\"][:]))\n",
    "        stacked_average_stats = stacked_average_stats * 1000\n",
    "\n",
    "        # In its final form stats_ref_array will have shape (20, 4, 20). The first 20 are the channels looked at, \n",
    "        # the 4 are the four stats seen in the comments below, and the last 20 will be the used reference channels.\n",
    "        if q ==0:\n",
    "            stats_ref_array = np.array((np.average(stacked_average_stats[:,0,:], axis=1), # Mean of mu\n",
    "                                        np.std(stacked_average_stats[:,0,:], axis=1), # Std dev of mu\n",
    "                                        np.average(stacked_average_stats[:,2,:], axis=1), # Mean of Sigma\n",
    "                                        np.std(stacked_average_stats[:,2,:], axis=1))).T # Std dev of sigma\n",
    "        else:\n",
    "            stats_ref_array = np.dstack((stats_ref_array,\n",
    "                                        np.array((np.average(stacked_average_stats[:,0,:], axis=1), # Mean of mu\n",
    "                                        np.std(stacked_average_stats[:,0,:], axis=1), # Std dev of mu\n",
    "                                        np.average(stacked_average_stats[:,2,:], axis=1), # Mean of Sigma\n",
    "                                        np.std(stacked_average_stats[:,2,:], axis=1))).T # Std dev of sigma\n",
    "                                        ))\n",
    "\n",
    "        number_stats_and_errors = len(stacked_average_stats[0,:,0])\n",
    "        average_stat_names = ['Mu', 'Sigma']\n",
    "\n",
    "        for k, stat in enumerate(average_stat_names):\n",
    "            for p in range(len(stacked_average_stats[:,k,0])):\n",
    "                if p%5==0: # to split the plots in the boards\n",
    "                    plt.figure()\n",
    "                    plt.xticks(range(len(stacked_average_stats[0,0,:])), included_runs)\n",
    "\n",
    "                    if stat=='Mu':\n",
    "                        plt.ylim((-mu_range, mu_range))\n",
    "                    if stat=='Sigma':\n",
    "                        plt.ylim((-sigma_range, sigma_range))\n",
    "\n",
    "                mean = np.mean(stacked_average_stats[p, 2*k, :])\n",
    "                std_dev = np.std(stacked_average_stats[p, 2*k, :])\n",
    "                plt.errorbar(range(len(stacked_average_stats[0,0,:])), stacked_average_stats[p, 2*k, :],\n",
    "                             yerr = stacked_average_stats[p, 2*k+1, :],\n",
    "                             label =f'Channel {to_channel_converter(p)}, Mean' + '{:.1e}'.format(mean) + ', Deviation:' + '{:.1e}'.format(std_dev))\n",
    "                plt.legend(loc='best')\n",
    "                plt.title(f'{measurement_name}' + f' {stat}, Reference Channel: {ref_channel}')\n",
    "\n",
    "                plt.xticks(np.arange(len(included_runs)), map(str, range(1, len(included_runs) + 1)))\n",
    "                plt.xlabel(f'{measurement_name}' + ' Run')\n",
    "                plt.ylabel('Time (ps)')\n",
    "                plt.savefig(variation_save + f'Variation Stats Board {letters[p//5]} Ref Channel {to_channel_converter(q)} {stat}.pdf', dpi = 300)\n",
    "            plt.show()\n",
    "\n",
    "            with h5py.File(variation_save_folder_global + '/' + f'{measurement_name}' + f' {measurement_date}' + ' Stats.h5', 'w') as hf:\n",
    "                    hf.create_dataset(\"stats\",  data=stats_ref_array)\n",
    "        \n",
    "            \n",
    "def variation_statistics(measurement_name, measurement_date, colormesh_max=10, within_board_plot=True):\n",
    "    \"\"\" Plots the mu and sigma and their errors of a measurement over several runs in colormesh plots.\n",
    "    \n",
    "    measurement_name -- (string) Title of the measurement, for example power cycle or temperature\n",
    "    measurement_date -- (string) Date of the measurement. Originally used to distinguish between series of runs, \n",
    "                        but the date will not be unique enough for future measurements.\n",
    "                        Could and should be replaced by a unique identifier, like an ID for a batch of runs.\n",
    "    colormesh_max -- (float) The maximum of the scale in the colormesh plot. Lowering this reveals finer differences, but blows out rough ones.\n",
    "    within_board_plot -- (boolean) Plots the average value of a statistic within the different boards. Still needs refinement as it does not properly\n",
    "                        handle erroneous channels as of now.\n",
    "    \"\"\"\n",
    "    \n",
    "    with h5py.File(variation_save_folder_global + '/' + f'{measurement_name}' + f' {measurement_date}' + ' Stats.h5', 'r') as hf:\n",
    "        stats_of_stats = hf[\"stats\"][:]\n",
    "\n",
    "    #print(stats_of_stats[:, :, 1], stats_of_stats.shape)\n",
    "\n",
    "    plot_titles = ['Mean of Mu', 'Std Dev of Mu', 'Mean of Sigma', 'Std Dev of Sigma']\n",
    "    variation_save = variation_save_folder_global + '/' + measurement_name + '/' + measurement_date + '/'\n",
    "    Path(variation_save).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Plotting\n",
    "    for k, ref_channel in enumerate(channel_names):\n",
    "        for i in range(len(stats_of_stats[0,:,0])):\n",
    "            \n",
    "            # Used for skipping means, they are not really interesting without the std dev\n",
    "            if (i == 0) or (i ==2):\n",
    "                continue\n",
    "            \n",
    "            # Visualizing the average value of a statistic within a board. The lowest one (desirable for std dev) is marked red.\n",
    "            if within_board_plot:\n",
    "                if k%5==0:\n",
    "                    within_board_performances = []\n",
    "                    for q in range(len(letters)):\n",
    "                        within_board_performances.append(np.mean(stats_of_stats[(q*len(numbers)):(q*len(numbers))+5, i, k]))\n",
    "                    within_board_performances = np.array(within_board_performances)\n",
    "                    print(within_board_performances)\n",
    "                    plt.figure()\n",
    "                    barlist = plt.bar(letters, height = within_board_performances)\n",
    "                    barlist[np.argmin(within_board_performances)].set_color('r')\n",
    "                    plt.title(f'{plot_titles[i]}: Within board performance for reference board {letters[k//5]}')\n",
    "                    plt.show()\n",
    "\n",
    "                \n",
    "            plt.figure()\n",
    "            stat_data = stats_of_stats[:, i, k].reshape(4,5)\n",
    "            c = plt.pcolormesh(X, Y, stat_data, vmin = 0, vmax = 10)\n",
    "            cb = plt.colorbar(c)\n",
    "            cb.set_label('Deviation over Temperature (ps)')\n",
    "            plt.title('Temperature Variation' + '\\n' +  f'{plot_titles[i]}, Reference Channel: {ref_channel}')\n",
    "            plt.savefig(variation_save + f'Variation Stats Colormesh {plot_titles[i]} Ref Channel {to_channel_converter(k)}.pdf', dpi = 300)      \n",
    "            plt.show()\n",
    "                \n",
    "\n",
    "\"\"\" Example uses \"\"\"       \n",
    "def example(number):\n",
    "    if number==1:\n",
    "        run_time_delta_computation(15500)\n",
    "    if number==2:\n",
    "        statistics_plot(15500)\n",
    "    if number==3:\n",
    "        variation_plot('Temperature Variation', '07.02.2022', \n",
    "                included_runs=[15483, 15484, 15487, 15489, 15490, 15491, 15492, 15493, 15500, 15503, 15511, 15513, 15516, 15524, 15525, 15527, 15533, 15541])\n",
    "    if number==4:\n",
    "        variation_statistics('Temperature Variation', '07.02.2022')\n",
    "        \n",
    "        \n",
    "\"\"\" January 2022 Data \n",
    "One can input these into the variation_plot function, or any of the runs into the run_time_delta_computation or statistics_plot functions.\n",
    "\"\"\"\n",
    "# included_runs = [15358, 15359, 15362, 15366] # Power cycle 1\n",
    "# included_runs = [15384, 15387, 15389, 15390, 15395, 15397, 15400, 15401] Power cycle 2\n",
    "# included_runs = [15483, 15484, 15487, 15489, 15490, 15491, 15492, 15493, 15500, 15503, 15511, 15513, 15516, 15524, 15525, 15527, 15533, 15541] # Temperature 07.02.2022\n",
    "# included_runs = [15373, 15387, 15422, 15533] # Variation over several days\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd0a621e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
